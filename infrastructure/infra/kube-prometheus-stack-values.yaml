# Grafana configuration for visualization
grafana:
  service:
    type: ClusterIP # Internal cluster access only, exposed via Ingress
  ingress:
    enabled: true
    ingressClassName: traefik
    hosts:
      - monitoring.baris.cloud-ip.cc
    path: /
    pathType: Prefix
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-staging # Auto-TLS via Cert-Manager
    tls:
      - secretName: grafana-tls
        hosts:
          - monitoring.baris.cloud-ip.cc
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "1"

  additionalDataSources:
    - name: Loki
      type: loki
      access: proxy
      url: http://loki-gateway.monitoring.svc.cluster.local
      jsonData:
        maxLines: 1000


# Prometheus configuration for data collection and storage
prometheus:
  prometheusSpec:
    # Essential: Discover ServiceMonitors across all namespaces (dev, prod, argocd, etc.)
    serviceMonitorSelectorNilUsesHelmValues: false
    # allow Prometheus to discover all rules
    ruleSelectorNilUsesHelmValues: false
    # allows Prometheus to find "probe" objects
    probeSelectorNilUsesHelmValues: false
    retention: 10d # Keep data for 10 days
  ingress:
    enabled: true
    ingressClassName: traefik
    hosts:
      - prometheus.baris.cloud-ip.cc
    path: /

alertmanager:
  enabled: true
  ingress:
    enabled: true
    ingressClassName: traefik
    hosts:
      - alerts.baris.cloud-ip.cc
    path: /
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-staging
    tls:
      - secretName: alertmanager-tls
        hosts:
          - alerts.baris.cloud-ip.cc

  alertmanagerSpec:
    useExistingConfig: false
    alertmanagerConfigSelectorNilUsesHelmValues: false
    alertmanagerConfigNamespaceSelectorNilUsesHelmValues: false

  config:
    global:
      smtp_smarthost: 'mailpit-smtp.monitoring.svc.cluster.local:25'
      smtp_from: 'alertmanager@baris.cloud-ip.cc'
      smtp_require_tls: false
    route:
      group_by: [ 'alertname', 'env' ]
      group_wait: 10s       # wait before sending the first notification
      group_interval: 60s   # wait between grouped alerts
      repeat_interval: 60s  # wait before repeating the same alert
      receiver: 'mailpit-notifications'
      routes:
        - matchers:
            - alertname = "Watchdog"
          receiver: 'null'
    receivers:
      - name: 'mailpit-notifications'
        email_configs:
          - to: 'admin@baris.cloud-ip.cc'
            send_resolved: true
            require_tls: false
            headers:
              Subject: >-
                [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] 
                {{ .GroupLabels.alertname }} 
                ({{ or .CommonLabels.env .CommonLabels.namespace "system" }})
      # used to silence some alerts, so nothing happens
      - name: 'null'

# Prometheus Operator core settings
prometheusOperator:
  manageCrds: true # Ensures CRDs (like ServiceMonitors) are installed/updated

# Global Alerting Rules managed by the Prometheus Operator
additionalPrometheusRulesMap:
  # One unified rule file for the entire Petclinic Application
  petclinic-availability-rules:
    groups:
      - name: app_health_alerts
        rules:
          # 1. Database Health (Internal connectivity)
          - alert: PostgresDown
            expr: pg_up == 0
            for: 10s
            labels:
              severity: critical
              component: database
              env: "{{ $labels.namespace }}"
            annotations:
              summary: "Health Alert: Database ({{ $labels.namespace }})"
              description: "The Postgres database in namespace {{ $labels.namespace }} is unreachable."

          # 2. Backend Health (Spring Boot via Blackbox)
          - alert: SpringBackendDown
            expr: probe_success{app="petclinic-backend"} == 0
            for: 10s
            labels:
              severity: critical
              component: backend
            annotations:
              summary: "Health Alert: Backend ({{ $labels.env }})"
              description: "Spring Boot is offline in {{ $labels.env }}. Target: {{ $labels.instance }}"

          # 3. Frontend Health (Angular via Blackbox)
          - alert: AngularFrontendDown
            expr: probe_success{app="petclinic-frontend"} == 0
            for: 10s
            labels:
              severity: critical
              component: frontend
            annotations:
              summary: "Health Alert: Frontend ({{ $labels.env }})"
              description: "Angular Frontend is offline in {{ $labels.env }}. Target: {{ $labels.instance }}"

kubeControllerManager:
  enabled: false
kubeProxy:
  enabled: false
kubeScheduler:
  enabled: false
